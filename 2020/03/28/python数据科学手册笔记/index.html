<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>&lt;Python数据科学手册&gt;笔记 - emacsist</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="emacsist" />
  <meta name="description" content="数据科学概念 它综合了三个领域的能力 统计学家 : 建立模型和聚合数" />

  <meta name="keywords" content="Golang, Java, PostgreSQL, Postgres, MySQL, emacsist, RabbitMQ, Go, emacs, orgmode" />






<meta name="generator" content="Hugo 0.57.0" />


<link rel="canonical" href="https://emacsist.github.io/2020/03/28/python%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/" />

<link href="." rel="alternate" type="application/rss+xml" title="emacsist" />
<link href="." rel="feed" type="application/rss+xml" title="emacsist" />



<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="manifest" href="/manifest.json">
<link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">




<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<link href="/dist/even.min.css?v=3.1.1" rel="stylesheet">





<meta property="og:title" content="&lt;Python数据科学手册&gt;笔记" />
<meta property="og:description" content="数据科学概念 它综合了三个领域的能力 统计学家 : 建立模型和聚合数" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://emacsist.github.io/2020/03/28/python%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6%E6%89%8B%E5%86%8C%E7%AC%94%E8%AE%B0/" />
<meta property="article:published_time" content="2020-03-28T22:44:37+08:00" />
<meta property="article:modified_time" content="2020-03-28T22:44:37+08:00" />
<meta itemprop="name" content="&lt;Python数据科学手册&gt;笔记">
<meta itemprop="description" content="数据科学概念 它综合了三个领域的能力 统计学家 : 建立模型和聚合数">


<meta itemprop="datePublished" content="2020-03-28T22:44:37&#43;08:00" />
<meta itemprop="dateModified" content="2020-03-28T22:44:37&#43;08:00" />
<meta itemprop="wordCount" content="9502">



<meta itemprop="keywords" content="python,数据," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="&lt;Python数据科学手册&gt;笔记"/>
<meta name="twitter:description" content="数据科学概念 它综合了三个领域的能力 统计学家 : 建立模型和聚合数"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">emacsist</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="/post/">
        <li class="mobile-menu-item">Archives</li>
      </a><a href="/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="/about/">
        <li class="mobile-menu-item">About</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="/" class="logo">emacsist</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/post/">Archives</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="/about/">About</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">&lt;Python数据科学手册&gt;笔记</h1>

      <div class="post-meta">
        <span class="post-time"> 2020-03-28 </span>
        
        <span class="more-meta"> 9502 words </span>
        <span class="more-meta"> 19 mins read </span>
        <span id="busuanzi_container_page_pv" class="more-meta"> <span id="busuanzi_value_page_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> times read </span>
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li><a href="#数据科学概念">数据科学概念</a></li>
<li><a href="#环境">环境</a>
<ul>
<li><a href="#jupyter-ipython">jupyter /ipython</a></li>
</ul></li>
<li><a href="#方便">方便</a>
<ul>
<li><a href="#jupyter">Jupyter</a></li>
<li><a href="#ipython">ipython</a></li>
</ul></li>
<li><a href="#numpy">NumPy</a>
<ul>
<li><a href="#理解动态类型">理解动态类型</a></li>
<li><a href="#固定元素类型-array-ndarray">固定元素类型 array/ndarray</a></li>
<li><a href="#numpy-初始化数组">numpy 初始化数组</a></li>
<li><a href="#numpy-的属性">NumPy 的属性</a></li>
<li><a href="#数组切片">数组切片</a></li>
<li><a href="#创建副本-copy-方法">创建副本: copy 方法</a></li>
<li><a href="#数组的变形">数组的变形</a></li>
<li><a href="#数组的拼接">数组的拼接</a></li>
<li><a href="#数组的分裂">数组的分裂</a></li>
<li><a href="#通用函数">通用函数</a>
<ul>
<li><a href="#高级通用函数">高级通用函数</a></li>
<li><a href="#聚合">聚合</a>
<ul>
<li><a href="#多维度聚合">多维度聚合</a></li>
<li><a href="#聚合函数">聚合函数</a></li>
</ul></li>
</ul></li>
<li><a href="#广播">广播</a>
<ul>
<li><a href="#规则">规则</a></li>
<li><a href="#实际应用">实际应用</a>
<ul>
<li><a href="#归一化">归一化</a></li>
<li><a href="#画一个二维函数">画一个二维函数</a></li>
</ul></li>
</ul></li>
<li><a href="#比较通用函数">比较通用函数</a></li>
<li><a href="#操作布尔数组">操作布尔数组</a>
<ul>
<li><a href="#布尔运算">布尔运算</a></li>
<li><a href="#掩码">掩码</a></li>
</ul></li>
<li><a href="#索引">索引</a></li>
<li><a href="#排序">排序</a></li>
<li><a href="#结构化数组">结构化数组</a></li>
<li><a href="#数据类型">数据类型</a>
<ul>
<li><a href="#复合类型">复合类型</a></li>
</ul></li>
</ul></li>
<li><a href="#pandas">Pandas</a>
<ul>
<li><a href="#基本数据结构">基本数据结构</a>
<ul>
<li><a href="#series">Series</a>
<ul>
<li><a href="#属性">属性</a></li>
<li><a href="#显式指定索引">显式指定索引</a></li>
<li><a href="#series-是特殊的字典">Series 是特殊的字典</a></li>
</ul></li>
<li><a href="#dataframe">DataFrame</a>
<ul>
<li><a href="#属性-1">属性</a></li>
<li><a href="#创建-dataframe-对象">创建 DataFrame 对象</a></li>
</ul></li>
<li><a href="#index">Index</a>
<ul>
<li><a href="#不可变数组">不可变数组</a></li>
<li><a href="#看成有序集合">看成有序集合</a></li>
</ul></li>
</ul></li>
<li><a href="#对象数据选择">对象数据选择</a>
<ul>
<li><a href="#series-1">Series</a></li>
<li><a href="#dataframe-1">DataFrame</a></li>
</ul></li>
<li><a href="#运算">运算</a>
<ul>
<li><a href="#索引对齐">索引对齐</a>
<ul>
<li><a href="#series-索引对齐">Series 索引对齐</a></li>
<li><a href="#dataframe-索引对齐">DataFrame 索引对齐</a></li>
<li><a href="#dataframe-与-series-运算">DataFrame 与 Series 运算</a></li>
</ul></li>
</ul></li>
<li><a href="#缺失值">缺失值</a>
<ul>
<li><a href="#处理缺失值">处理缺失值</a></li>
<li><a href="#多级索引-series">多级索引 Series</a>
<ul>
<li><a href="#笨办法">笨办法</a></li>
<li><a href="#pandas-多级索引">Pandas 多级索引</a></li>
</ul></li>
<li><a href="#多级索引的创建">多级索引的创建</a>
<ul>
<li><a href="#通过字典来创建">通过字典来创建</a></li>
</ul></li>
<li><a href="#多级索引的等级名">多级索引的等级名</a></li>
<li><a href="#多级列索引">多级列索引</a></li>
<li><a href="#多级索引的取值与切片">多级索引的取值与切片</a>
<ul>
<li><a href="#series-2">Series</a></li>
<li><a href="#dataframe-2">DataFrame</a></li>
</ul></li>
<li><a href="#多级索引其他">多级索引其他</a>
<ul>
<li><a href="#索引排序">索引排序</a></li>
<li><a href="#索引-stack-与-unstack">索引 stack 与 unstack</a></li>
<li><a href="#索引的设置与重置">索引的设置与重置</a></li>
<li><a href="#多级索引的数据统计方法">多级索引的数据统计方法</a></li>
</ul></li>
<li><a href="#concat-与-append">concat 与 append</a></li>
<li><a href="#索引重复">索引重复</a></li>
<li><a href="#忽略索引">忽略索引</a></li>
<li><a href="#增加多级索引">增加多级索引</a></li>
<li><a href="#类似-join-合并">类似 join 合并</a></li>
<li><a href="#append-方法">append 方法</a></li>
</ul></li>
<li><a href="#join-与-merge">join 与 merge</a>
<ul>
<li><a href="#merge">merge</a>
<ul>
<li><a href="#指定合并键">指定合并键</a></li>
</ul></li>
<li><a href="#join">join</a></li>
<li><a href="#合并规则">合并规则</a></li>
<li><a href="#重名列">重名列</a></li>
</ul></li>
<li><a href="#数据累计">数据累计</a></li>
<li><a href="#groupby">groupBy</a>
<ul>
<li><a href="#aggregate-filter-transform-apply">aggregate, filter, transform, apply</a></li>
<li><a href="#设置-groupby-的-键">设置 GroupBy 的 键</a></li>
</ul></li>
<li><a href="#数据透视表">数据透视表</a></li>
<li><a href="#处理字符串">处理字符串</a></li>
<li><a href="#处理时间序列">处理时间序列</a>
<ul>
<li><a href="#numpy-的-datetime64-类型">NumPy 的 datetime64 类型</a></li>
<li><a href="#pandas-的-timestamp">Pandas 的 Timestamp</a></li>
<li><a href="#pandas-时间序列">Pandas 时间序列</a></li>
<li><a href="#有规律的时间序列">有规律的时间序列</a></li>
<li><a href="#频率文档">频率文档</a></li>
<li><a href="#获取股价">获取股价</a></li>
<li><a href="#重新取样与频率转换">重新取样与频率转换</a></li>
<li><a href="#移动均值">移动均值</a></li>
</ul></li>
<li><a href="#高性能运算">高性能运算</a>
<ul>
<li><a href="#eval">eval</a></li>
<li><a href="#query">query</a></li>
</ul></li>
<li><a href="#matplotlib">Matplotlib</a></li>
<li><a href="#显示">显示</a></li>
<li><a href="#保存为文件">保存为文件</a></li>
<li><a href="#两种画图接口">两种画图接口</a>
<ul>
<li><a href="#matlab-风格">matlab 风格</a></li>
<li><a href="#面向对象接口">面向对象接口</a></li>
</ul></li>
<li><a href="#线条的颜色与风格">线条的颜色与风格</a></li>
<li><a href="#坐标轴上下限">坐标轴上下限</a></li>
<li><a href="#设置图形标签">设置图形标签</a></li>
<li><a href="#面向对象风格设置">面向对象风格设置</a></li>
<li><a href="#误差线">误差线</a></li>
<li><a href="#图例">图例</a></li>
</ul></li>
<li><a href="#机器学习">机器学习</a>
<ul>
<li><a href="#分类">分类</a></li>
<li><a href="#scikit-learn-数据表示">Scikit-Learn 数据表示</a>
<ul>
<li><a href="#数据表">数据表</a></li>
<li><a href="#特征矩阵">特征矩阵</a></li>
<li><a href="#目标数组">目标数组</a></li>
</ul></li>
<li><a href="#scikit-learn-评估器api">Scikit-Learn 评估器API</a>
<ul>
<li><a href="#有监督学习示例-线性回归">有监督学习示例 : 线性回归</a></li>
<li><a href="#有监督学习示例-鸢尾花数据分类">有监督学习示例: 鸢尾花数据分类</a></li>
<li><a href="#无监督学习示例-鸢尾花数据降维">无监督学习示例: 鸢尾花数据降维</a></li>
<li><a href="#无监督学习示例-鸢尾花数据聚类">无监督学习示例: 鸢尾花数据聚类</a></li>
</ul></li>
<li><a href="#超参考与模型验证">超参考与模型验证</a>
<ul>
<li><a href="#模型验证-model-validation">模型验证(model validation)</a></li>
<li><a href="#偏差与方差的均衡">偏差与方差的均衡</a></li>
<li><a href="#验证曲线">验证曲线</a></li>
<li><a href="#学习曲线">学习曲线</a></li>
</ul></li>
<li><a href="#特征工程">特征工程</a>
<ul>
<li><a href="#分类特征">分类特征</a></li>
<li><a href="#文本特征">文本特征</a></li>
<li><a href="#图像特征">图像特征</a></li>
<li><a href="#缺失值填充">缺失值填充</a></li>
</ul></li>
<li><a href="#朴素贝叶斯分类">朴素贝叶斯分类</a>
<ul>
<li><a href="#高斯朴素贝叶斯">高斯朴素贝叶斯</a></li>
<li><a href="#多项式朴素贝叶斯">多项式朴素贝叶斯</a></li>
</ul></li>
<li><a href="#线性回归">线性回归</a></li>
<li><a href="#支持向量机-svm">支持向量机 SVM</a></li>
</ul></li>
<li><a href="#杂项">杂项</a></li>
</ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      

<h1 id="数据科学概念">数据科学概念</h1>

<p>它综合了三个领域的能力</p>

<ul>
<li>统计学家 :  建立模型和聚合数据</li>
<li>计算机科学家 :  设计并使用算法对数据进行高效存储,  分析和可视化</li>
<li>领域专家 : 有细分领域中经过专业训练, 既可提出正确的问题, 又可作出专业的解答</li>
</ul>

<h1 id="环境">环境</h1>

<p><a href="https://www.anaconda.com/distribution/#download-section">https://www.anaconda.com/distribution/#download-section</a></p>

<p><a href="https://mirror.tuna.tsinghua.edu.cn/help/anaconda/">https://mirror.tuna.tsinghua.edu.cn/help/anaconda/</a></p>

<pre><code class="language-bash">conda install numpy pandas scikit-learn matplotlib seaborn ipython-notebook
</code></pre>

<h2 id="jupyter-ipython">jupyter /ipython</h2>

<pre><code class="language-bash">ipython

jupyter notebook
</code></pre>

<h1 id="方便">方便</h1>

<h2 id="jupyter">Jupyter</h2>

<p>在 Jupyter 查看帮助文档</p>

<ul>
<li><code>?</code> : 比如 <code>len?</code> 或 <code>对象.方法名?</code></li>
<li><code>??</code> : 获取源码. 例如 <code>square??</code></li>
<li><code>&lt;TAB&gt;</code> : 自动补全</li>
<li>通配: <code>str.*find*?</code> 或 <code>*Warning?</code></li>
</ul>

<h2 id="ipython">ipython</h2>

<ul>
<li><code>%paste 或 %cpaste</code> : 从粘贴板里粘贴代码块并排版</li>
<li><code>%run</code> : 执行外部代码. 例如 <code>%run myscript.py</code></li>
<li>代码耗时

<ul>
<li><code>%time</code> : 对单个语句执进行计时</li>
<li><code>%timeit</code> : 对单个语句重复执行进行计时</li>
<li><code>%%timeit</code> : 计算多行代码的耗时</li>
<li><code>%prun</code> : 利用分析器运行代码. 例如 <code>%prun sum_of_lists(1000000)</code></li>
<li><code>%lprun</code> : 利用逐行分析器运行代码. 要安装扩展 <code>pip install line_profiler, 然后导入 %load_ext line_profiler</code></li>
<li><code>%memit</code> : 测量单个语句的内存使用. 要安装扩展 <code>pip install memory_profiler, 然后导入 %load_ext memory_profiler</code></li>
<li><code>%mprun</code> : 通逐行的内存分析器运行代码. 扩展同上.</li>
</ul></li>
<li><code>%magic</code> : 查看 magic 函数的使用</li>
<li><code>%lsmagic</code> : 查看所有 magic 相关的函数</li>
<li><code>In 和 OUT 对象</code> : <code>print(In)</code>, 引用相应的对象 <code>In[N]</code>

<ul>
<li>OUT 对象不包括 None 的输出</li>
<li>禁止输出. 在语句后面添加分号 <code>;</code></li>
</ul></li>
<li><code>%history -n 1-4</code> : 列出历史第 1到 4 条命令</li>
<li><code>!ls</code> : 执行外部命令 <code>ls</code></li>
<li><code>contents = !ls</code> : 保存外部命令的输出</li>
<li><code>%xmode Verbose</code> : 控制异常信息</li>
<li><code>%debug</code> : 调试</li>
</ul>

<h1 id="numpy">NumPy</h1>

<h2 id="理解动态类型">理解动态类型</h2>

<p>Python 中的整型不仅仅是一个整型, 标准的 Python 实现是用 C 语言编写的. 这意味着每一个 Python 对象都是一个聪明的伪 C 语言结构体, 该结构体不仅包含其值, 还有其他信息. 例如 Python 中 long 的定义如下</p>

<pre><code class="language-c">struct _longobject { 
	long ob_refcnt;
	PyTypeObject *ob_type; 
  size_t ob_size;
	long ob_digit[1];
};
</code></pre>

<p>分别为</p>

<ul>
<li>引用计数</li>
<li>类型编码</li>
<li>对象大小</li>
<li>实际值</li>
</ul>

<p>即 Python 对象的 <code>ObjectHeader</code></p>

<blockquote>
<p>Python 中的列表元素也是, 可以不相同的类型</p>
</blockquote>

<h2 id="固定元素类型-array-ndarray">固定元素类型 array/ndarray</h2>

<blockquote>
<p>Python 3.3 之后</p>
</blockquote>

<pre><code class="language-python">import array
L = list(range(10))
A = array.array('i', L)
</code></pre>

<ul>
<li><code>'i'</code> : 表示类型码, 这里为整型</li>
</ul>

<p>也可以用 <code>NumPy</code> 的 <code>ndarray</code></p>

<p>ndarray 可以显式指定元素类型: <code>np.array([1,2,3], dtype='float32')</code></p>

<h2 id="numpy-初始化数组">numpy 初始化数组</h2>

<pre><code class="language-python">np.zeros(10, dtype=int)

# 3*5 (3行, 5列)
np.ones((3,5), dtype=float)

# 3行 5列, 每个元素都初始化为 3.14
np.full((3,5), 3.14)

# 5 个元素, 均匀地分配到范围 0~1
np.linspace(0, 1, 5)

# 3*3 , 每个元素为 0~1 的随机数
np.random.random((3,3))

# 3*3, 均值为 0, 标准差为 1 的正态分布的随机数组
np.random.normal(0, 1, (3,3))

# 3*3, [0, 10) 区间的随机整型数组
np.random.randint(0, 10, (3, 3))

# 单位矩阵, 3*3
np.eye(3)

# 3 个整数组成的数组, 元素是当前内存中的任意值
np.empty(3)
</code></pre>

<h2 id="numpy-的属性">NumPy 的属性</h2>

<ul>
<li><code>ndim</code> : 数组的维度</li>
<li><code>shape</code> : 数组每个维度的大小</li>
<li><code>size</code> : 数组的总大小. 每个维度的大小的乘积.</li>
<li><code>dtype</code> : 元素类型</li>
<li><code>itemsize</code> : 元素字节大小</li>
<li><code>nbytes</code> : 数组总字节大小. 一般可认为 <code>itemsize * size</code></li>
</ul>

<blockquote>
<p>索引从 0 开始</p>

<p>索引 -1 表示最后一个元素</p>

<p>多维数组中, 可用逗号分隔的索引元组来索引. 例如 [1, 5]</p>
</blockquote>

<h2 id="数组切片">数组切片</h2>

<p><code>x[start:stop:step]</code>, 要特别注意的是它返回的是数据的<code>视图</code>, 而不是数据的副本. 而在 <code>python 列表中, 切片是副本</code>.</p>

<ul>
<li><code>x[:5]</code> : 前 5 个元素</li>
<li><code>x[5:]</code> : 后 5 个元素</li>
<li><code>x[4:7]</code> : 中间子元素</li>
<li><code>x[::2]</code> : 每隔一个元素</li>
<li><code>x[::-1]</code> : 逆序元素</li>
<li><code>x[5::-2]</code> : 从索引 5 开始, 每隔一个元素逆序</li>
</ul>

<p>多维切片同理, 在每个维度中, 采用上面类似的处理, 用逗号分隔</p>

<ul>
<li><code>x2[:3, :2]</code> : 三行, 两列</li>
</ul>

<p>获取数组的行和列</p>

<ul>
<li><code>x2[:, 0]</code> : x2 的第一列</li>
<li><code>x2[0, :]</code> : x2 的第一行, 更简的写法为 <code>x2[0]</code></li>
</ul>

<h2 id="创建副本-copy-方法">创建副本: copy 方法</h2>

<p><code>x2[:2, :2].copy()</code></p>

<h2 id="数组的变形">数组的变形</h2>

<p><code>reshape()</code> 方法</p>

<pre><code class="language-python">grid = np.arange(1, 10).reshape((3,3))
print(grid)
</code></pre>

<h2 id="数组的拼接">数组的拼接</h2>

<ul>
<li><code>np.concatenate</code> : 例如 . <code>np.concatenate([x, y]), 其中 x=[1,2,3], y=[3,2,1]</code></li>
<li><code>np.vstack</code> : 垂直栈拼接</li>
<li><code>np.hstack</code> : 水平栈拼接</li>
</ul>

<h2 id="数组的分裂">数组的分裂</h2>

<ul>
<li><code>np.split</code> : <code>np.split(要分裂的数组, 分裂点)</code>

<ul>
<li><code>np.split(x, [N])</code> 表示分裂为<code>x[0:N], x[N:]</code></li>
<li><code>np.split(x, [N,M])</code> 表示分裂为 <code>x[0:N], x[N:M], x[M:]</code></li>
</ul></li>
<li><code>np.hsplit</code> : 即按列分割</li>
<li><code>np.vsplit</code> : 即按行分割</li>
</ul>

<h2 id="通用函数">通用函数</h2>

<p>NumPy 快的关键是利用 <code>向量化</code> 操作, 这通常在 NumPy 的 <code>ufunc</code> (通用函数) 中实现.</p>

<blockquote>
<p>scipy.special 模块也提供了类似的通用函数. 它提供更丰富的数学函数</p>
</blockquote>

<p><code>x=np.range(4)</code></p>

<p><code>theta = np.linspace(0, np.pi, 3)</code></p>

<ul>
<li>数组的运算: 如 <code>x + 5</code></li>
<li>绝对值. <code>np.abs(x)</code></li>
<li>三角函数: <code>np.sin(theta)</code></li>
<li>指数和对数: <code>np.exp(x), np.exp2(x), np.power(3, x)</code></li>
<li>专用通用函数. <code>scipy.special</code> 模块. <code>from scipy import special</code></li>
</ul>

<h3 id="高级通用函数">高级通用函数</h3>

<ul>
<li><code>指定输出</code>. 所有的通用函数都可以通过 <code>out</code> 参数来指定计算结果的存放位置</li>
<li><code>聚合</code>. <code>reduce</code> 一个数组, 它会对给定的元素和操作重复执行, 直到得到单个结果. 如 <code>np.add.reduce(x)</code></li>
<li><code>外积</code>. 对两个输入数组所有元素对应函数运算结果. 如 <code>np.multiply.outer(x, x)</code></li>
</ul>

<h3 id="聚合">聚合</h3>

<ul>
<li>求和 <code>sum(x)</code> 或 <code>np.sum(x)</code> (这个更好)</li>
<li>最大/最小值: <code>min(x), max(x)</code> 或 <code>np.min(x), np.max(x)</code>  或 <code>x.min(), x.max(), x.sum()</code></li>
</ul>

<h4 id="多维度聚合">多维度聚合</h4>

<p><code>x.min(axis=0)</code></p>

<p>通过 <code>axis</code> 参数来指定维度. 默认情况下是所有.</p>

<h4 id="聚合函数">聚合函数</h4>

<table>
<thead>
<tr>
<th>函数</th>
<th>NaN 安全版本</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>np.sum</code></td>
<td><code>np.nansum</code></td>
<td>元素求和</td>
</tr>

<tr>
<td><code>np.prod</code></td>
<td><code>np.nanprod</code></td>
<td>元素的积</td>
</tr>

<tr>
<td><code>np.mean</code></td>
<td><code>np.nanmean</code></td>
<td>元素的平均值</td>
</tr>

<tr>
<td><code>np.std</code></td>
<td><code>np.nanstd</code></td>
<td>元素的标准差</td>
</tr>

<tr>
<td><code>np.var</code></td>
<td><code>np.nanvar</code></td>
<td>元素的方差</td>
</tr>

<tr>
<td><code>np.min</code></td>
<td><code>np.nanmin</code></td>
<td>元素最小值</td>
</tr>

<tr>
<td><code>np.max</code></td>
<td><code>np.nanmax</code></td>
<td>元素的最大值</td>
</tr>

<tr>
<td><code>np.argmin</code></td>
<td><code>np.nanargmin</code></td>
<td>元素最小值的索引</td>
</tr>

<tr>
<td><code>np.argmax</code></td>
<td><code>np.nanargmax</code></td>
<td>元素最大值的索引</td>
</tr>

<tr>
<td><code>np.median</code></td>
<td><code>np.nanmedian</code></td>
<td>元素的中位数</td>
</tr>

<tr>
<td><code>np.percentile</code></td>
<td><code>np.nanpercentile</code></td>
<td>基于元素排序的统计值</td>
</tr>

<tr>
<td><code>np.any</code></td>
<td>没有</td>
<td>元素是否存在为真</td>
</tr>

<tr>
<td><code>np.all</code></td>
<td>没有</td>
<td>所有元素是否为真</td>
</tr>
</tbody>
</table>

<h2 id="广播">广播</h2>

<p><code>用于不同大小数组的二元通用函数的一组规则</code></p>

<p><img src="/img/image-20200326113609713.png" alt="image-20200326113609713" /></p>

<h3 id="规则">规则</h3>

<ul>
<li>如果两个数组的维度数不相同, 那么小的维度数组的形状将会在最左边补 1</li>
<li>如果两个数组的形状在任何一个维度上都不匹配, 那么数组的形状会沿着维度为 1 的维度扩展以匹配另外一个数组的形状</li>
<li>如果两个数组的形状在任何一个维度上都不匹配并且没有任何一个维度等于 1, 那么会引发异常</li>
</ul>

<h3 id="实际应用">实际应用</h3>

<h4 id="归一化">归一化</h4>

<pre><code class="language-python">X = np.random.random((10, 3))
Xmean = X.mean(0)
X_centered = X - Xmean
</code></pre>

<h4 id="画一个二维函数">画一个二维函数</h4>

<pre><code class="language-python">%matplotlib inline
import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(0, 5, 50)
y = np.linspace(0, 5, 50)[:, np.newaxis]

z = np.sin(x) ** 10 + np.cos(10 + y*x) * np.cos(x)

plt.imshow(z, origin='lower', extent=[0, 5, 0, 5], cmap='viridis')
plt.colorbar()
</code></pre>

<h2 id="比较通用函数">比较通用函数</h2>

<table>
<thead>
<tr>
<th>运算</th>
<th>对应通用函数</th>
</tr>
</thead>

<tbody>
<tr>
<td><code>==</code></td>
<td><code>np.equal</code></td>
</tr>

<tr>
<td><code>!=</code></td>
<td><code>np.not_equal</code></td>
</tr>

<tr>
<td><code>&lt;</code></td>
<td><code>np.less</code></td>
</tr>

<tr>
<td><code>&lt;=</code></td>
<td><code>np.less_equal</code></td>
</tr>

<tr>
<td><code>&gt;</code></td>
<td><code>np.greater</code></td>
</tr>

<tr>
<td><code>&gt;=</code></td>
<td><code>np.greater_equal</code></td>
</tr>
</tbody>
</table>

<pre><code class="language-python">rng = np.random.RandomState(0)
x = rng.randint(10, size=(3, 4))
x &lt; 6
</code></pre>

<h2 id="操作布尔数组">操作布尔数组</h2>

<pre><code class="language-python">x = [[5 0 3 3]
      [7 9 3 5]
      [2 4 7 6]]
</code></pre>

<ul>
<li>统计个数: <code>np.count_nonzero(x &lt; 6)</code> 或 <code>np.sum(x&lt;6)</code> (False 为 0, True 为 1)</li>
<li>检查是否存在: <code>np.any(x&gt;8)</code> 表示有没有大于 8 的值</li>
<li>检查所有: <code>np.all(x &lt; 8, axis=0)</code> 表示0 维度的所有元素是否都小于 8. 不写维度表示所有</li>
</ul>

<h3 id="布尔运算">布尔运算</h3>

<ul>
<li><code>&amp;</code>  : 位与</li>
<li><code>|</code> : 位或</li>
<li><code>^</code>:  异或</li>

<li><p><code>~</code> : 取反</p>

<pre><code class="language-python">rng = np.random.RandomState(0)
x = rng.randint(10, size=(3, 4)) 

print(&quot;大于 0 的个数&quot;, np.sum(x &gt; 0))
print(&quot;等于 0 的个数&quot;, np.sum(x == 0))
print(&quot;大于 5 的个数&quot;, np.sum(x &gt; 5))
print(&quot;大于 5 且小于 8 的个数&quot;, np.sum((x &gt; 5) &amp; (x &lt; 8)) )
</code></pre></li>
</ul>

<h3 id="掩码">掩码</h3>

<p>选择器</p>

<pre><code class="language-python">rng = np.random.RandomState(0)
x = rng.randint(10, size=(3, 4)) 

# 即将 x 各个元素小于 5 的筛选出来
x[x &lt; 5]
</code></pre>

<h2 id="索引">索引</h2>

<ul>
<li><code>x[0]</code></li>
<li><code>x[:5]</code></li>
<li><code>x[x&lt;5]</code></li>

<li><p><code>fancy indexing</code> : 它传递的是索引数组, 而不是单个标量.  <code>结果是索引数组的形状</code>. 它返回的值反映的是 <code>广播后的索引数组的形状</code></p>

<pre><code class="language-python">x = [51 92 14 71 60 20 82 86 74 74]
ind = [3, 7, 4]
x[ind]
# 修改
x[ind] = 99
</code></pre></li>
</ul>

<h2 id="排序">排序</h2>

<ul>
<li><code>np.sort</code> : 快速排序

<ul>
<li>对每一行排序: <code>np.sort(x, axis=1)</code></li>
<li>对每一列排序: <code>np.sort(x, axis=0)</code></li>
<li>注意, 上面是分别排序, 任何行或列之间的关系将丢失!</li>
</ul></li>
<li><code>np.argsort</code> : 它返回的是原始数组排好序的<code>索引值</code></li>
<li>分隔: <code>np.partition(x, k)</code> : 返回一个新的数组, 最左边是第 K 小的值, 右边是任意顺序的其他元素. 两个部分都是任意排序的!</li>
</ul>

<h2 id="结构化数组">结构化数组</h2>

<pre><code class="language-python">name = ['Alice', 'Bob', 'Cathy', 'Doug']
age = [25, 45, 37, 19]
weight = [55.0, 85.5, 68.0, 61.5]


data = np.zeros(4, dtype={'names':('name', 'age', 'weight'),
                           'formats':('U10', 'i4', 'f8')})
data['name'] = name
data['age'] = age
data['weight'] = weight
print(data)

# 获取年龄小于30岁的人的名字
data[data['age'] &lt; 30]['name']
</code></pre>

<h2 id="数据类型">数据类型</h2>

<p>格式为</p>

<ul>
<li>第一个可选字符是 <code>&lt;</code> (低字节序)或 <code>&gt;</code> (高字节序)</li>
<li>第二个是数据的类型

<ul>
<li><code>'b'</code> : 字节</li>
<li><code>'i'</code> : 有符号整型</li>
<li><code>'u'</code> : 无符号整型</li>
<li><code>'f'</code> : 浮点型</li>
<li><code>'c'</code> : 复数浮点型</li>
<li><code>'S', 'a'</code> : 字符串</li>
<li><code>'U'</code> : Unicode 编码字符串</li>
<li><code>'V'</code> : 原生数据</li>
</ul></li>
<li>最后一个字符表示该对象的字节大小</li>
</ul>

<p><code>dtype([('name', '&lt;U10'), ('age', '&lt;i8'), ('weight', '&lt;f4')])</code></p>

<h3 id="复合类型">复合类型</h3>

<p>用 <code>mat</code> 来表示矩阵</p>

<pre><code class="language-python">tp = np.dtype([('id', 'i8'), ('mat', 'f8', (3, 3))])
X = np.zeros(1, dtype=tp)
print(X[0])
</code></pre>

<h1 id="pandas">Pandas</h1>

<blockquote>
<p>DataFrame 本质上是一种带行标签和列标签, 支持相同类型数据和缺失值的多维数组</p>
</blockquote>

<h2 id="基本数据结构">基本数据结构</h2>

<h3 id="series">Series</h3>

<p><code>一个带索引数据构成的一维数组</code></p>

<pre><code class="language-python">data = pd.Series([0.25, 0.5, 0.75, 1.0])
data
</code></pre>

<p>输出为</p>

<pre><code class="language-python">0    0.25
1    0.50
2    0.75
3    1.00
dtype: float64
</code></pre>

<h4 id="属性">属性</h4>

<ul>
<li><code>values</code></li>
<li><code>index</code></li>
</ul>

<h4 id="显式指定索引">显式指定索引</h4>

<pre><code class="language-python">data = pd.Series([0.25, 0.5, 0.75, 1.0], index=['a', 'b', 'c', 'd'])
data
data['b']

# 不连续的也可以
data = pd.Series([0.25, 0.5, 0.75, 1.0], index=[2, 5, 3, 7])
data[5]
</code></pre>

<h4 id="series-是特殊的字典">Series 是特殊的字典</h4>

<p>用 python 内置的字典秋创建 Series 对象时, 其索引默认按顺序排列.</p>

<pre><code class="language-python">population_dict = {'California': 38332521, 'Texas': 26448193,
                                'New York': 19651127,
                                'Florida': 19552860,
                                'Illinois': 12882135}
population = pd.Series(population_dict) 
population

# 输出为
California    38332521
Texas         26448193
New York      19651127
Florida       19552860
Illinois      12882135
dtype: int64
  
# 获取数据
population['California']
# 也可使用切片
population['California':'Illinois']
</code></pre>

<h3 id="dataframe">DataFrame</h3>

<p>可作用一个通用型 NumPy 数组, 也可以看作特殊的 Python 字典</p>

<p>如果 Series 是灵活的一维数组, 那可以将 DataFrame 看作灵活的二维数组</p>

<pre><code class="language-python">population_dict = {'California': 38332521, 'Texas': 26448193,
                                'New York': 19651127,
                                'Florida': 19552860,
                                'Illinois': 12882135}
population = pd.Series(population_dict) 

area_dict = {'California': 423967, 'Texas': 695662, 'New York': 141297,
'Florida': 170312, 'Illinois': 149995} 
area = pd.Series(area_dict)

states = pd.DataFrame({'population': population, 'area': area})
states
</code></pre>

<p>输出为</p>

<pre><code class="language-python">						population	area
California	38332521	423967
Texas				26448193	695662
New York		19651127	141297
Florida			19552860	170312
Illinois		12882135	149995
</code></pre>

<h4 id="属性-1">属性</h4>

<ul>
<li><code>index</code></li>
<li><code>columns</code></li>
</ul>

<h4 id="创建-dataframe-对象">创建 DataFrame 对象</h4>

<pre><code class="language-python"># 通过 Series 创建
pd.DataFrame(population, columns=['population'])

# 通过字典创建
data = [{'a': i, 'b': 2 * i} for i in range(3)]
pd.DataFrame(data)

# 通过 series 对象创建
states = pd.DataFrame({'population': population, 'area': area})

# 通过 NumPy 二维数组创建
pd.DataFrame(np.random.rand(3, 2), columns=['foo', 'bar'], index=['a', 'b', 'c'])

# 通过 NumPy 结构化数组创建
A = np.zeros(3, dtype=[('A', 'i8'), ('B', 'f8')])
pd.DataFrame(A)
</code></pre>

<h3 id="index">Index</h3>

<p>可以将它看作是一个<code>不可变数组</code> 或 <code>有序集合(实际是一个多集 ,Index 对象可能包含重复值)</code></p>

<h4 id="不可变数组">不可变数组</h4>

<blockquote>
<p>不可以 ind[0] = newValue</p>
</blockquote>

<pre><code class="language-python">ind = pd.Index([2, 3, 5, 7, 11])
# 它还有许多属性
print(ind.size, ind.shape, ind.ndim, ind.dtype)
</code></pre>

<h4 id="看成有序集合">看成有序集合</h4>

<pre><code class="language-python">indA = pd.Index([1, 3, 5, 7, 9]) 
indB = pd.Index([2, 3, 5, 7, 11])

# 交集
indA &amp; indB

# 并集
indA | indB

# 异或
indA ^ indB
</code></pre>

<h2 id="对象数据选择">对象数据选择</h2>

<h3 id="series-1">Series</h3>

<pre><code class="language-python">import pandas as pd
data = pd.Series([0.25, 0.5, 0.75, 1.0],index=['a', 'b', 'c', 'd'])
data

# 看作字典
data['a']
'a' in data
data.keys()
list(data.items())
# 添加数据
data['e'] = 1.25

# 看作一维数组
data['a':'c']
data[0:2]
# 掩码
data[ (data &gt; 0.3) &amp; (data &lt; 0.8) )
# fancy index
data[['a', 'e']]     
</code></pre>

<blockquote>
<p>data = pd.Series([&lsquo;a&rsquo;, &lsquo;b&rsquo;, &lsquo;c&rsquo;], index=[1, 3, 5])</p>

<p>整数索引容易混乱.</p>

<p>data[1] 会使用显式索引</p>

<p>而</p>

<p>data[1:3] 会使用隐式索引</p>
</blockquote>

<p>可通过索引器来为显式指定</p>

<pre><code class="language-python"># 结果为 a
data.loc[1]
</code></pre>

<p>python 形式的隐式指定</p>

<pre><code class="language-python"># 结果为 b
data.iloc[1]
</code></pre>

<h3 id="dataframe-1">DataFrame</h3>

<pre><code class="language-python">area = pd.Series({'California': 423967, 'Texas': 695662, 'New York': 141297, 'Florida': 170312,
'Illinois': 149995})
pop = pd.Series({'California': 38332521, 'Texas': 26448193,
                              'New York': 19651127, 'Florida': 19552860,
'Illinois': 12882135})
data = pd.DataFrame({'area':area, 'pop':pop})

# 看作字典, 下面两个都可以
data['area']
# 纯字符串的才可以, 建议少数这种, 避免冲突
data.area
# 增加一列
data['density'] = data['pop'] / data['area']

# 看作二维数组
data.values
# 进行转置
data.T
# 获取一行数据
data.values[0]
# 获取某列
data['area']
# python 隐式索引获取数据
data.iloc[:3, :2]
data.loc[:'Illinois', :'pop']
# 混合上面两种
data.ix[:3, :'pop']
# fancy index
data.loc[data.density &gt; 100, ['pop', 'density']]
# 过虑行
data[data.density &gt; 100]

# 如果 index 是日期类型
data['2010-01-01':'2010-02-01']
</code></pre>

<h2 id="运算">运算</h2>

<p>对于一元运算, 它会在输出结果中<code>保留索引和列标签</code></p>

<p>对于二元运算, 在传递通用函数时会自动<code>对齐索引</code>进行计算</p>

<h3 id="索引对齐">索引对齐</h3>

<h4 id="series-索引对齐">Series 索引对齐</h4>

<pre><code class="language-python">area = pd.Series({'Alaska': 1723337, 'Texas': 695662, 'California': 423967}, name='area')

population = pd.Series({'California': 38332521, 'Texas': 26448193, 'New York': 19651127}, name='population')

population / area
</code></pre>

<p><code>结果数组的索引是两个输入数组索引的并集</code> . 缺失值用 <code>NaN</code> 来填充. 也可以指定缺失值</p>

<p><code>A.add(B, fill_value=0)</code></p>

<h4 id="dataframe-索引对齐">DataFrame 索引对齐</h4>

<pre><code class="language-python">A = pd.DataFrame(rng.randint(0, 20, (2, 2)),columns=list('AB'))
B = pd.DataFrame(rng.randint(0, 10, (3, 3)),columns=list('BAC'))

A + B
# 指定缺失值
fill = A.stack().mean()
A.add(B, fill_value=fill)
</code></pre>

<h4 id="dataframe-与-series-运算">DataFrame 与 Series 运算</h4>

<p>这与二维数组与一维数组的运算规则一样</p>

<h2 id="缺失值">缺失值</h2>

<ul>
<li><code>None</code> : 它是一个 Python 对象, 所以不能作为任何 NumPy / Pandas 数组类型的缺失值, 只能用于 <code>object</code> 数组类型</li>
<li><code>NaN</code> : 数值类型的缺失值. 无论与 NaN 进行何种操作, 最终结果都是 NaN. 用 <code>np.nan</code> 表示. <code>它是一种特殊的浮点数</code></li>
</ul>

<blockquote>
<p>Pandas 中是把它们看成等价交换的</p>
</blockquote>

<h3 id="处理缺失值">处理缺失值</h3>

<ul>
<li><code>isnull()</code> : 创建一个布尔类型的掩码标签缺失值</li>
<li><code>notnull()</code> : 与 isnull 操作相反</li>
<li><code>dropna()</code> : 返回一个剔除缺失值的数据

<ul>
<li>对于 DataFrame , 要么是剔除缺失值所在的整行, 要么是整列.<code>默认是剔除整行数据</code></li>
<li><code>df.dropna(axis='columns')</code> : 剔除任何包含缺失值的整列数据</li>
<li><code>df.dropna(axis='rows', thresh=3)</code></li>
<li><code>thresh</code> : <code>非缺失值</code>的最小数量. 即该行中非缺失值的数量 <code>&gt;=3</code> 就保留</li>
</ul></li>

<li><p><code>fillna()</code> : 返回一个填充了缺失值的数据副本</p>

<ul>
<li><code>data.fillna(method='ffill')</code> : 用缺失值前面的有效值来从前往后填充<code>forward-fill</code></li>
<li><code>data.fillna(method='bfill')</code> : 用缺失值后面的有效值来从后往前填充<code>back-fill</code></li>

<li><p>DataFrame 类似 <code>df.fillna(method='ffill', axis=1)</code> . 只是在填充时设置坐标轴参数 axis</p>

<pre><code class="language-python">data = pd.Series([1, np.nan, 'hello', None])

data.isnull()
data[data.notnull()]
</code></pre></li>
</ul></li>
</ul>

<h3 id="多级索引-series">多级索引 Series</h3>

<h4 id="笨办法">笨办法</h4>

<pre><code class="language-python">index = [('California', 2000), ('California', 2010),
                     ('New York', 2000), ('New York', 2010),
                     ('Texas', 2000), ('Texas', 2010)]
populations = [33871648, 37253956,
               18976457, 19378102,
               20851820, 25145561]
pop = pd.Series(populations, index=index)

pop[('California', 2010):('Texas', 2000)]

pop[[i for i in pop.index if i[1] == 2010]]
</code></pre>

<h4 id="pandas-多级索引">Pandas 多级索引</h4>

<pre><code class="language-python">index = pd.MultiIndex.from_tuples(index)
# 笨办法上面的 pop
pop = pop.reindex(index)

# 输出结果为
California  2000    33871648
            2010    37253956
New York    2000    18976457
            2010    19378102
Texas       2000    20851820
            2010    25145561
dtype: int64

# 等同笨办法的 
# pop[[i for i in pop.index if i[1] == 2010]]
pop[:, 2010]
</code></pre>

<p>将一个多级索引的 Series 转化为普通索引的 DataFrame</p>

<pre><code class="language-python">pop_df = pop.unstack()
# 再转回多级索引
new_pop = pop_df.stack()
</code></pre>

<p>可以利用多级索引来表示任意维度的数据</p>

<h3 id="多级索引的创建">多级索引的创建</h3>

<p>最直接的办法是将 index 参数设置为至少二维的索引数组</p>

<pre><code class="language-python">df = pd.DataFrame(np.random.rand(4, 2), index=[['a', 'a', 'b', 'b'], [1, 2, 1, 2]],columns=['data1', 'data2'])
df
</code></pre>

<p>结果为</p>

<pre><code class="language-python">		data1	data2
a	1	0.511362	0.973176
	2	0.079617	0.493073
b	1	0.623067	0.475468
	2	0.246864	0.120539
</code></pre>

<h4 id="通过字典来创建">通过字典来创建</h4>

<pre><code class="language-python">data = {('California', 2000): 33871648,
                     ('California', 2010): 37253956,
                     ('Texas', 2000): 20851820,
                     ('Texas', 2010): 25145561,
                     ('New York', 2000): 18976457,
                     ('New York', 2010): 19378102}
 pd.Series(data)
</code></pre>

<h3 id="多级索引的等级名">多级索引的等级名</h3>

<pre><code class="language-python">pop.index.names = ['state', 'year']
</code></pre>

<h3 id="多级列索引">多级列索引</h3>

<pre><code class="language-python"># 多级行列索引
index = pd.MultiIndex.from_product([[2013, 2014], [1, 2]],
names=['year', 'visit'])
columns = pd.MultiIndex.from_product([['Bob', 'Guido', 'Sue'], ['HR', 'Temp']],
                                          names=['subject', 'type'])
# 模拟数据
data = np.round(np.random.randn(4, 6), 1) 
data[:, ::2] *= 10
data += 37
# 创建DataFrame
health_data = pd.DataFrame(data, index=index, columns=columns) 
health_data
</code></pre>

<p><img src="/img/image-20200326234142115.png" alt="image-20200326234142115" /></p>

<h3 id="多级索引的取值与切片">多级索引的取值与切片</h3>

<h4 id="series-2">Series</h4>

<pre><code class="language-python">index = [('California', 2000), ('California', 2010),
                     ('New York', 2000), ('New York', 2010),
                     ('Texas', 2000), ('Texas', 2010)]
populations = [33871648, 37253956,
               18976457, 19378102,
               20851820, 25145561]
pop = pd.Series(populations, index=index)
index = pd.MultiIndex.from_tuples(index)
pop = pop.reindex(index)
pop.index.names=['state', 'year']
pop
</code></pre>

<p><img src="/img/image-20200326234633493.png" alt="image-20200326234633493" /></p>

<pre><code class="language-python"># 获取单个元素
pop['California', 2000]

# 获取局部
pop['California']

# 切片
pop.loc['California':'New York']

pop[:, 2000]

# 过虑
pop[pop &gt; 22000000]

# fancy index
pop[['California', 'Texas']]
</code></pre>

<h4 id="dataframe-2">DataFrame</h4>

<p><img src="/img/image-20200326234904123.png" alt="image-20200326234904123" /></p>

<pre><code class="language-python">health_data['Guido', 'HR']

health_data.iloc[:2, :2]

health_data.loc[:, ('Bob', 'HR')]
</code></pre>

<h3 id="多级索引其他">多级索引其他</h3>

<h4 id="索引排序">索引排序</h4>

<blockquote>
<p>切片最好要索引有序的</p>
</blockquote>

<pre><code class="language-python">data = data.sort_index()
# 之后切片
data['a':'b']
</code></pre>

<h4 id="索引-stack-与-unstack">索引 stack 与 unstack</h4>

<p>将多级索引数据转换为二维形式</p>

<pre><code class="language-python">pop.unstack(level=0)

pop.unstack(level=1)
</code></pre>

<p>stack 是 unstack 的逆操作</p>

<h4 id="索引的设置与重置">索引的设置与重置</h4>

<pre><code class="language-python">pop_flat.set_index(['state','year'])
pop_flat = pop.reset_index(name='population')
</code></pre>

<h4 id="多级索引的数据统计方法">多级索引的数据统计方法</h4>

<p><img src="/img/image-20200326235738429.png" alt="image-20200326235738429" /></p>

<pre><code class="language-python">data_mean = health_data.mean(level='year')

data_mean.mean(axis=1, level='type')
</code></pre>

<h3 id="concat-与-append">concat 与 append</h3>

<p>默认情况下 <code>concat</code> 是按行的</p>

<pre><code class="language-python">ser1 = pd.Series(['A', 'B', 'C'], index=[1, 2, 3]) 
ser2 = pd.Series(['D', 'E', 'F'], index=[4, 5, 6]) 
pd.concat([ser1, ser2])
</code></pre>

<p>输出为</p>

<pre><code class="language-python">1    A
2    B
3    C
4    D
5    E
6    F
dtype: object
</code></pre>

<p>按列 concat</p>

<pre><code class="language-python">pd.concat([df3, df4], axis='col')
</code></pre>

<h3 id="索引重复">索引重复</h3>

<p>如果想检测是否有重复, 有的话检查异常</p>

<pre><code class="language-python">try:
	pd.concat([x, y], verify_integrity=True)
except ValueError as e: 
  print(&quot;ValueError:&quot;, e)
</code></pre>

<h3 id="忽略索引">忽略索引</h3>

<pre><code class="language-python"># 如果将参数设置为 True，那么合并时将会创建一个新的整数索引
pd.concat([x, y], ignore_index=True)
</code></pre>

<h3 id="增加多级索引">增加多级索引</h3>

<pre><code class="language-python">pd.concat([x, y], keys=['x', 'y'])
</code></pre>

<h3 id="类似-join-合并">类似 join 合并</h3>

<pre><code class="language-python"># 相同的列名才合并
pd.concat([df5, df6], join='inner')

# 指定列名合并
pd.concat([df5, df6], join_axes=[df5.columns])
</code></pre>

<h3 id="append-方法">append 方法</h3>

<pre><code class="language-python">df1.append(df2)
</code></pre>

<h2 id="join-与-merge">join 与 merge</h2>

<p>提供类似数据库的操作</p>

<h3 id="merge">merge</h3>

<p><code>pd.merge()</code> 实现了三种数据连接类型</p>

<ul>
<li>一对一</li>
<li>多对一</li>

<li><p>多对多</p>

<pre><code class="language-python"># merge 会自动判断 df1, df2 中相同的列名(不一定要求顺序), 然后以该相同的列进行 merge
df3 = pd.merge(df1, df2)
</code></pre></li>
</ul>

<h4 id="指定合并键">指定合并键</h4>

<pre><code class="language-python"># df1, df2 有相同的列名才可用
pd.merge(df1, df2, on='employee')

# df1 使用 employee, df2 使用 name 来进行 merge
pd.merge(df1, df3, left_on=&quot;employee&quot;, right_on=&quot;name&quot;)
# 删除多余列
pd.merge(df1, df3, left_on=&quot;employee&quot;, right_on=&quot;name&quot;).drop('name', axis=1)
</code></pre>

<p>合并索引</p>

<pre><code class="language-python">pd.merge(df1a, df2a, left_index=True, right_index=True)
</code></pre>

<h3 id="join">join</h3>

<p>它是按照索引进行数据合并</p>

<pre><code class="language-python">df1a.join(df2a)

# 指定索引名
pd.merge(df1a, df3, left_index=True, right_on='name')
</code></pre>

<h3 id="合并规则">合并规则</h3>

<pre><code class="language-python"># 内联. 这是默认行为
pd.merge(df6, df7, how='inner')
</code></pre>

<p>how 可支持</p>

<ul>
<li><p><code>inner</code> : 默认. 交集</p></li>

<li><p><code>'outer'</code> : 并集. 缺失值用 NaN 填充</p></li>

<li><p><code>'left'</code> : 左连接, 表示结果只包含左列</p></li>

<li><p><code>'right'</code>: 右连接, 表示结果只包含右列</p></li>
</ul>

<h3 id="重名列">重名列</h3>

<p><code>pd.merge()</code> 会自动加后缀. 也可指定</p>

<pre><code class="language-python">pd.merge(df8, df9, on=&quot;name&quot;, suffixes=[&quot;_L&quot;, &quot;_R&quot;])
</code></pre>

<h2 id="数据累计">数据累计</h2>

<pre><code class="language-python"># Series
rng = np.random.RandomState(42)
ser = pd.Series(rng.rand(5))

ser.sum()
ser.mean()

# DataFrame. 累计函数默认对每列进行统计
df = pd.DataFrame({'A': rng.rand(5), 'B': rng.rand(5)})
df.mean()
# 对每一行进行统计
df.mean(axis='columns')
# 计算每一列的若干常用统计值
df.dropna().describe()

</code></pre>

<p>Pandas 内置统计方法.</p>

<ul>
<li><code>count()</code></li>
<li><code>first()</code></li>
<li><code>last()</code></li>
<li><code>mean()</code></li>
<li><code>median()</code></li>
<li><code>min()</code></li>
<li><code>max()</code></li>
<li><code>std()</code> : 标准差</li>
<li><code>var</code> : 方差</li>
<li><code>mad()</code> : 均值绝对偏差</li>
<li><code>prod()</code> : 所有项乘积</li>
<li><code>sum()</code> : 所有项求和</li>
</ul>

<h2 id="groupby">groupBy</h2>

<p>它会进行: <code>分割(split)</code> -&gt; <code>应用(apply)</code> -&gt; <code>组合(combine)</code></p>

<pre><code class="language-python">df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],
                                'data': range(6)}, columns=['key', 'data'])
df.groupby('key').sum()
</code></pre>

<p>其他示例<code>planets.groupby('method')['orbital_period'].median()</code></p>

<p>按组迭代</p>

<pre><code class="language-python">for (method, group) in planets.groupby('method'):
  print(&quot;{0:30s} shape={1}&quot;.format(method, group.shape))
</code></pre>

<p>调用方法</p>

<pre><code class="language-python">planets.groupby('method')['year'].describe().unstack()
</code></pre>

<h3 id="aggregate-filter-transform-apply">aggregate, filter, transform, apply</h3>

<pre><code class="language-python">rng = np.random.RandomState(0)
df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],
                   'data1': range(6),
                   'data2': rng.randint(0, 10, 6)},
                  columns = ['key', 'data1', 'data2'])

# 聚合 aggregate
df.groupby('key').aggregate(['min', np.median, max])
# 在每一列指定统计函数
df.groupby('key').aggregate({'data1': 'min', 'data2': 'max'})

# 过虑 filter
def filter_func(x):
	return x['data2'].std() &gt; 4

df.groupby('key').filter(filter_func)

# 转换 transform
df.groupby('key').transform(lambda x: x - x.mean())

# 应用. apply
def norm_by_data2(x):
	# x是一个分组数据的DataFrame
	x['data1'] /= x['data2'].sum() 
  return x
df.groupby('key').apply(norm_by_data2)
</code></pre>

<h3 id="设置-groupby-的-键">设置 GroupBy 的 键</h3>

<pre><code class="language-python"># 将列表、数组、Series 或索引作为分组键
L = [0, 1, 0, 1, 2, 0]
df.groupby(L).sum()
df.groupby(df['key']).sum()

# 用字典或 Series 将索引映射到分组名称
df2 = df.set_index('key')
mapping = {'A': 'vowel', 'B': 'consonant', 'C': 'consonant'}
df2.groupby(mapping).sum()

# 任意 Python 函数
df2.groupby(str.lower).mean()

# 多个有效键构成的列表
df2.groupby([str.lower, mapping]).mean()
</code></pre>

<h2 id="数据透视表">数据透视表</h2>

<p>Pivot table, 它将每一列数据作为输入, 输出将数据不断细分成多个维度统计信息的二维数据表. 更像是一种<code>多维的 GroupBy 统计</code>操作.</p>

<pre><code class="language-python">import numpy as np
import pandas as pd
import seaborn as sns

# wget -c https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv

# 普通使用
titanic = sns.load_dataset('titanic')
titanic.groupby('sex')[['survived']].mean()
titanic.groupby(['sex', 'class'])['survived'].aggregate('mean').unstack()

# 通过 pivot_table 方式
titanic.pivot_table('survived', index='sex', columns='class')

age = pd.cut(titanic['age'], [0, 18, 80])
titanic.pivot_table('survived', ['sex', age], 'class')
</code></pre>

<p>pivot_table 方法完整签名(0.18 Pandas 版本)</p>

<pre><code class="language-python">DataFrame.pivot_table(data, values=None, index=None, columns=None,
aggfunc='mean', fill_value=None, margins=False, dropna=True, margins_name='All')
</code></pre>

<h2 id="处理字符串">处理字符串</h2>

<p>如果只是简单地处理, 在数据出现缺失值, 会引起异常. 如</p>

<pre><code class="language-python">data = ['peter', 'Paul', None, 'MARY', 'gUIDO']
[s.capitalize() for s in data]

# 这时可用 Pandas 的 str 属性来处理
names = pd.Series(data)
names.str.capitalize()
</code></pre>

<p>Pandas 所有可处理的字符串方法都可 <code>pandas对象.str.XXXX()</code>  , 如 <code>names.str.lower()</code></p>

<h2 id="处理时间序列">处理时间序列</h2>

<blockquote>
<p>Pandas 最初是为金融模型而创建的</p>
</blockquote>

<p>原生</p>

<pre><code class="language-python">from datetime import datetime
from dateutil import parser

datetime(year=2015, month=7, day=4)

date = parser.parse(&quot;4th of July, 2015&quot;)
date.strftime('%A')
</code></pre>

<p>格式化字符 <a href="https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior">https://docs.python.org/3/library/datetime.html#strftime-strptime-behavior</a></p>

<h3 id="numpy-的-datetime64-类型">NumPy 的 datetime64 类型</h3>

<pre><code class="language-python">import numpy as np
date = np.array('2015-07-04', dtype=np.datetime64)

date + np.arange(12)

np.datetime64('2015-07-04')
# 设置单位
np.datetime64('2015-07-04 12:59:59.50', 'ns')
</code></pre>

<h3 id="pandas-的-timestamp">Pandas 的 Timestamp</h3>

<pre><code class="language-python">import pandas as pd
date = pd.to_datetime(&quot;4th of July, 2015&quot;) 
date
date.strftime('%A')

# 向量化计算 
date + pd.to_timedelta(np.arange(12), 'D')
</code></pre>

<h3 id="pandas-时间序列">Pandas 时间序列</h3>

<pre><code class="language-python">index = pd.DatetimeIndex(['2014-07-04', '2014-08-04', '2015-07-04', '2015-08-04'])
data = pd.Series([0, 1, 2, 3], index=index)

# 切片
data['2014-07-04':'2015-07-04']
</code></pre>

<ul>
<li>时间戳: <code>Timestamp</code></li>
<li>周期数据: <code>Period</code></li>
<li>时间增量: <code>Timedelta</code></li>
</ul>

<p>任何 DatetimeIndex 都可以通过 <code>to_period()</code> 转换成 PeriodIndex:</p>

<pre><code class="language-python"># to_datetime 的参数是时间序列, 则会返回一个 DatetimeIndex
dates = pd.to_datetime([datetime(2015, 7, 3), '4th of July, 2015', '2015-Jul-6', '07-07-2015', '20150708'])

dates.to_period('D')
</code></pre>

<p>TimedeltaIndex : 用一个日期减另一个日期时就会返回 TimedeltaIndex</p>

<pre><code class="language-python">dates - dates[0]
</code></pre>

<h3 id="有规律的时间序列">有规律的时间序列</h3>

<p><code>pd.date_range()</code></p>

<pre><code class="language-python">pd.date_range('2015-07-03', '2015-07-10')
pd.date_range('2015-07-03', periods=8)
# 默认是 D
pd.date_range('2015-07-03', periods=8, freq='H')

pd.period_range('2015-07', periods=8, freq='M')

# 以时间递增的序列
pd.timedelta_range(0, periods=10, freq='H')
</code></pre>

<h3 id="频率文档">频率文档</h3>

<p><a href="https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases">https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases</a></p>

<h3 id="获取股价">获取股价</h3>

<pre><code class="language-python"># conda install pandas-datareader

from pandas_datareader import data
goog = data.DataReader('GOOG', start='2004', end='2016', data_source='google')
goog.head()
</code></pre>

<h3 id="重新取样与频率转换">重新取样与频率转换</h3>

<pre><code class="language-python">from pandas_datareader import data
goog = data.DataReader('GOOG', start='2004', end='2016', data_source='google')
goog = goog['Close']


%matplotlib inline
import matplotlib.pyplot as plt
import seaborn
seaborn.set()

goog.plot();

goog.plot(alpha=0.5, style='-') 
# 重新取样
goog.resample('BA').mean().plot(style=':') 

# 频率转换
goog.asfreq('BA').plot(style='--'); 
plt.legend(['input', 'resample', 'asfreq'],
                        loc='upper left');
</code></pre>

<h3 id="移动均值">移动均值</h3>

<pre><code class="language-python"> DataFrame.rolling(center=False,window=D).mean()
</code></pre>

<h2 id="高性能运算">高性能运算</h2>

<h3 id="eval">eval</h3>

<pre><code class="language-python">import pandas as pd
nrows, ncols = 100000, 100
rng = np.random.RandomState(42)
df1, df2, df3, df4 = (pd.DataFrame(rng.rand(nrows, ncols)) for i in range(4))

# 获取局部变量, 可以用 @变量名

%timeit df1 + df2 + df3 + df4
%timeit pd.eval('df1 + df2 + df3 + df4')
</code></pre>

<p>支持的运算</p>

<ul>
<li>算术运算</li>
<li>比较运算</li>
<li>位运算</li>
<li>对象属性与索引</li>
</ul>

<h3 id="query">query</h3>

<pre><code class="language-python"># 获取局部变量, 可以用 @变量名
result2 = df.query('A &lt; 0.5 and B &lt; 0.5')
</code></pre>

<h2 id="matplotlib">Matplotlib</h2>

<blockquote>
<p>import matplotlib as mpl</p>

<p>import matplotlib.pyplot as plt</p>
</blockquote>

<h2 id="显示">显示</h2>

<ul>
<li>脚本环境 : <code>plt.show()</code></li>
<li>IPython 环境: <code>%matplotlib; import matplotlib.pyplot as plt</code> . 强制刷新: <code>plt.draw()</code></li>
<li>IPython Notebook 环境

<ul>
<li><code>%matplotlib notebook</code> : Notebook 中启动交互式图形</li>
<li><code>%matplotlib inline</code> : Notebook 中启动静态图形</li>
</ul></li>
</ul>

<h2 id="保存为文件">保存为文件</h2>

<pre><code class="language-python">fig = plt.figure()
fig.savefig('my_figure.png')

# 导入图像文件
from IPython.display import Image
Image('my_figure.png')

# 查看支持的图片文件格式
fig.canvas.get_supported_filetypes()
</code></pre>

<h2 id="两种画图接口">两种画图接口</h2>

<h3 id="matlab-风格">matlab 风格</h3>

<p>位于 <code>pyplot</code> 接口中</p>

<pre><code class="language-python">plt.figure() # 创建图形
# 创建两个子图中的第一个，设置坐标轴 
plt.subplot(2, 1, 1) # (行、列、子图编号) 
plt.plot(x, np.sin(x))
# 创建两个子图中的第二个，设置坐标轴 
plt.subplot(2, 1, 2)
plt.plot(x, np.cos(x))
</code></pre>

<p>这种接口最重要的特性是<code>有状态的(stateful)</code>:它会持续跟踪“当前的”图形和坐标轴， 所有 plt 命令都可以应用.你可以用 <code>plt.gcf()</code> (获取当前图形)和 <code>plt.gca()</code>(获取当前 坐标轴)来查看具体信息.</p>

<h3 id="面向对象接口">面向对象接口</h3>

<pre><code class="language-python"># 先创建图形网格
# ax是一个包含两个Axes对象的数组
fig, ax = plt.subplots(2)
# 在每个对象上调用plot()方法 
ax[0].plot(x, np.sin(x)) 
ax[1].plot(x, np.cos(x))
</code></pre>

<h2 id="线条的颜色与风格">线条的颜色与风格</h2>

<pre><code class="language-python"># 颜色
plt.plot(x, np.sin(x - 0), color='blue') 
plt.plot(x, np.sin(x - 1), color='g') 
plt.plot(x, np.sin(x - 2), color='0.75') 
plt.plot(x, np.sin(x - 3), color='#FFDD44') 
plt.plot(x, np.sin(x - 4), color=(1.0,0.2,0.3)) 
plt.plot(x, np.sin(x - 5), color='chartreuse');

# 风格
plt.plot(x, x + 0, linestyle='solid') 
plt.plot(x, x + 1, linestyle='dashed') 
plt.plot(x, x + 2, linestyle='dashdot') 
plt.plot(x, x + 3, linestyle='dotted')
# 风格缩写形式
plt.plot(x, x + 4, linestyle='-')
plt.plot(x, x + 5, linestyle='--') 
plt.plot(x, x + 6, linestyle='-.') 
plt.plot(x, x + 7, linestyle=':')

# 风格与颜色组合
plt.plot(x, x + 0, '-g')
plt.plot(x, x + 1, '--c')
</code></pre>

<h2 id="坐标轴上下限">坐标轴上下限</h2>

<pre><code class="language-python">plt.xlim(10, 0) 
plt.ylim(1.2, -1.2)

# 或
plt.axis([-1, 11, -1.5, 1.5]);

# 自动根据内容收紧坐标轴
plt.axis('tight')
</code></pre>

<h2 id="设置图形标签">设置图形标签</h2>

<pre><code class="language-python">plt.title(&quot;A Sine Curve&quot;)
plt.xlabel(&quot;x&quot;) 
plt.ylabel(&quot;sin(x)&quot;)
</code></pre>

<h2 id="面向对象风格设置">面向对象风格设置</h2>

<pre><code class="language-python">ax = plt.axes() ax.plot(x, np.sin(x))
ax.set(xlim=(0, 10), ylim=(-2, 2), xlabel='x', ylabel='sin(x)',
                    title='A Simple Plot');
</code></pre>

<h2 id="误差线">误差线</h2>

<pre><code class="language-python">x = np.linspace(0, 10, 50) 
dy = 0.8
y = np.sin(x) + dy * np.random.randn(50) 
plt.errorbar(x, y, yerr=dy, fmt='.k')
</code></pre>

<h2 id="图例">图例</h2>

<pre><code class="language-python">ax.legend(fancybox=True, framealpha=1, shadow=True, borderpad=1)

# 控制图例显示的元素. 默认会忽略不设置标签的元素
plt.plot(x, y[:, 0], label='first') 
plt.plot(x, y[:, 1], label='second') 
plt.plot(x, y[:, 2:]) 
plt.legend(framealpha=1, frameon=True)
</code></pre>

<h1 id="机器学习">机器学习</h1>

<blockquote>
<p>机器学习是从数据创建模型的学问</p>
</blockquote>

<h2 id="分类">分类</h2>

<ul>
<li>有监督学习

<ul>
<li>分类 : 标签是离散值</li>
<li>回归 : 标签是连续值</li>
</ul></li>
<li>无监督学习

<ul>
<li>聚类 : 将数据分成不同的组别</li>
<li>降维 : 用更简洁的方式表现数据</li>
</ul></li>
</ul>

<h2 id="scikit-learn-数据表示">Scikit-Learn 数据表示</h2>

<h3 id="数据表">数据表</h3>

<p>基本的数据表就是二维网格数据，其中的每一行表示数据集中的每个样本，而列表示构成 每个样本的相关特征</p>

<p>行: 称为样表. <code>n_samples</code></p>

<p>列: 称为特征. <code>n_features</code></p>

<h3 id="特征矩阵">特征矩阵</h3>

<p>数据表通过二维数据或矩阵的形式将信息表达出来, 这类矩阵称为特征矩阵. 简记为变量 <code>X</code> . 它是维度为 <code>[n_samples, n_features]</code> 的二维矩阵.</p>

<h3 id="目标数组">目标数组</h3>

<p>简记为<code>y</code> . 目标数组一般是一维数组, 其长度就是样本总数 <code>n_samples</code> . 通常用一维的 NumPy 或 Pandas 的 Series 表示.</p>

<h2 id="scikit-learn-评估器api">Scikit-Learn 评估器API</h2>

<p>使用步骤</p>

<ol>
<li>从 Scikit-Learn 中导入适当的评估器, 选择模型类</li>
<li>用合适的数值对模型进行实例化, 配置模型超参数</li>
<li>整理数据, 获取特征矩阵和目标数组</li>
<li>调用模型实例的<code>fit()</code> 方法对数据进行拟合</li>
<li>对新数据应用模型.

<ul>
<li>对有监督学习模型中, 通常使用 <code>predict()</code> 方法预测新数据的标签</li>
<li>对无监督学习模型中, 通常使用 <code>transform()</code> 或 <code>predict()</code> 方法转换或推断数据的性质</li>
</ul></li>
</ol>

<h3 id="有监督学习示例-线性回归">有监督学习示例 : 线性回归</h3>

<pre><code class="language-python">import matplotlib.pyplot as plt 
import numpy as np

rng = np.random.RandomState(42) 
x = 10 * rng.rand(50)
y = 2 * x - 1 + rng.randn(50) 
plt.scatter(x, y);

</code></pre>

<ol>
<li>选择模型 : <code>from sklearn.linear_model import LinearRegression</code>

<ul>
<li>常见的线性模型:  <a href="http://scikit-learn.org/stable/modules/linear_model.html">http://scikit-learn.org/stable/modules/linear_model.html</a></li>
</ul></li>
<li>选择模型超参数. 有一些重要的参数, 必须在选择模型类时确定好. 这些参数通常称为 <code>超参数</code> , 即在模型拟合数据之前必须被确定的参数. <code>model = LinearRegression(fit_intercept=True)</code>  (这只是存储了超参数的值, 还没将模型应用到数据上. Scikit-Learn 将 <code>选择模型</code> 和 <code>将模型应用到数据</code> 区别)</li>
<li>将数据整理成特征矩阵和目标数组. <code>X = x[:, np.newaxis]</code></li>
<li>用模型拟合数据: <code>model.fit(X, y)</code></li>
<li>预测新数据的标签. <code>新数据</code> 是特征矩阵的 x 坐标值. 要用模型预测出目标数组的 y 轴坐标: <code>xfit = np.linspace(-1, 11)</code>

<ol>
<li>将 x 转换成 <code>[n_samples, n_feature]</code> 的特征矩阵形式, 输入到模型中: <code>Xfit = xfit[:, np.newaxis]</code></li>
<li>用模型预测: <code>yfit = model.predict(Xfit)</code></li>
</ol></li>
</ol>

<p>可视化结果</p>

<pre><code class="language-python">plt.scatter(x, y)
plt.plot(xfit, yfit);
</code></pre>

<p>完整代码</p>

<pre><code class="language-python">import matplotlib.pyplot as plt 
import numpy as np

# 数据
rng = np.random.RandomState(42) 
x = 10 * rng.rand(50)
y = 2 * x - 1 + rng.randn(50) 
plt.scatter(x, y)

# 选择模型
from sklearn.linear_model import LinearRegression

# 配置超参数
model = LinearRegression(fit_intercept=True)

# 整理特征矩阵
X = x[:, np.newaxis]

# 拟合数据
model.fit(X, y)

# 要预测数据
xfit = np.linspace(-1, 11)
Xfit = xfit[:, np.newaxis]

# 预测
yfit = model.predict(Xfit)

# 可视化
plt.scatter(x, y)
plt.plot(xfit, yfit)
</code></pre>

<h3 id="有监督学习示例-鸢尾花数据分类">有监督学习示例: 鸢尾花数据分类</h3>

<blockquote>
<p>高斯朴素贝叶斯 : 这个 方法假设每个特征中属于每一类的观测值都符合高斯分布</p>
</blockquote>

<p>分割数据为训练集和测试集</p>

<pre><code class="language-python">import seaborn as sns

iris = sns.load_dataset('iris')

# 特征矩阵和目标数组抽取
X_iris = iris.drop('species', axis=1)
y_iris = iris['species']

# 分割训练集 train 和测试集 test
from sklearn.model_selection import train_test_split
Xtrain, Xtest, ytrain, ytest = train_test_split(X_iris, y_iris, random_state=1)

# 选择高斯朴素贝叶斯(Gaussian naive Bayes) 模型
from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
# 拟合数据
model.fit(Xtrain, ytrain)

# 用测试集数据测试
y_model = model.predict(Xtest)

# 判断准确率
from sklearn.metrics import accuracy_score 
accuracy_score(ytest, y_model)
</code></pre>

<h3 id="无监督学习示例-鸢尾花数据降维">无监督学习示例: 鸢尾花数据降维</h3>

<blockquote>
<p>主成分分析(principal component analysis，PCA) : 一种快速线性降维技术</p>
</blockquote>

<pre><code class="language-python">from sklearn.decomposition import PCA
import seaborn as sns

iris = sns.load_dataset('iris')
X_iris = iris.drop('species', axis=1)
y_iris = iris['species']


# 配置超参数
model = PCA(n_components=2)

# 拟合数据
model.fit(X_iris)

# 将数据转换为二维
X_2D = model.transform(X_iris)

# 显示结果
iris['PCA1'] = X_2D[:, 0] 
iris['PCA2'] = X_2D[:, 1]
sns.lmplot(&quot;PCA1&quot;, &quot;PCA2&quot;, hue='species', data=iris, fit_reg=False);
</code></pre>

<h3 id="无监督学习示例-鸢尾花数据聚类">无监督学习示例: 鸢尾花数据聚类</h3>

<blockquote>
<p>聚类算法是要对没有任何标签的数据集进行分组.</p>

<p>高斯混合模型(Gaussian mixture model，GMM), GMM 模型试图将数据构造成若干服从高斯分布的概率密度 函数簇。</p>
</blockquote>

<pre><code class="language-python"># 1.选择模型类 
from sklearn.mixture import GaussianMixture
import seaborn as sns
from sklearn.decomposition import PCA

iris = sns.load_dataset('iris')
X_iris = iris.drop('species', axis=1)
y_iris = iris['species']

model = PCA(n_components=2)
model.fit(X_iris)
X_2D = model.transform(X_iris)
iris['PCA1'] = X_2D[:, 0] 
iris['PCA2'] = X_2D[:, 1]

# 2.设置超参数，初始化模型 
model = GaussianMixture(n_components=3,covariance_type='full') 

# 3.拟合数据，注意不需要y变量 
model.fit(X_iris)

# 4. 确定簇标签
y_gmm = model.predict(X_iris) 

# 可视化
iris['cluster'] = y_gmm
sns.lmplot(&quot;PCA1&quot;, &quot;PCA2&quot;, data=iris, hue='species',col='cluster', fit_reg=False);
</code></pre>

<h2 id="超参考与模型验证">超参考与模型验证</h2>

<h3 id="模型验证-model-validation">模型验证(model validation)</h3>

<p>选择模型和超参数之后，通过对训练数据进行学习，对比模型对已知数据的预测值与实际值的差异.</p>

<p>正确方法: 即将数据分成训练习和测试集</p>

<pre><code class="language-python">from sklearn.model_selection import train_test_split
# 每个数据集分一半数据
X1, X2, y1, y2 = train_test_split(X, y, random_state=0, train_size=0.5)

# 用模型拟合训练数据 
model.fit(X1, y1)
# 在测试集中评估模型准确率 
y2_model = model.predict(X2) 
accuracy_score(y2, y2_model)
</code></pre>

<p>更好的是: 交叉检验. 也就是做一组拟合，让数据的每个子集既是训练集，又 是验证集</p>

<pre><code class="language-python">y2_model = model.fit(X1, y1).predict(X2)
y1_model = model.fit(X2, y2).predict(X1) 

accuracy_score(y1, y1_model), accuracy_score(y2, y2_model)

# 自动处理
from sklearn.cross_validation import cross_val_score 
# 将数据分成 5 组, 每一轮依次用模型拟合其中的四组数据, 再预测第五组数据, 评估模型准确率
cross_val_score(model, X, y, cv=5)
</code></pre>

<h3 id="偏差与方差的均衡">偏差与方差的均衡</h3>

<ul>
<li>高偏差, 对数据欠拟合</li>
<li>高方差, 对数据过拟合</li>
<li>$R^2$ : 判断系数, 用来衡量模型与目标值均值的对比结果

<ul>
<li>为 1, 表示模型与数据完全吻合</li>
<li>为 0, 表示模型不比简单取均值好</li>
<li>为负, 表示模型性能很差</li>
</ul></li>
</ul>

<h3 id="验证曲线">验证曲线</h3>

<pre><code class="language-python">from sklearn.preprocessing import PolynomialFeatures 
from sklearn.linear_model import LinearRegression 
from sklearn.pipeline import make_pipeline

def PolynomialRegression(degree=2, **kwargs):
    return make_pipeline(PolynomialFeatures(degree), LinearRegression(**kwargs))
  
  
import numpy as np

def make_data(N, err=1.0, rseed=1): # 随机抽样数据
    rng = np.random.RandomState(rseed) 
    X = rng.rand(N, 1) ** 2
    y = 10 - 1. / (X.ravel() + 0.1)
    if err &gt; 0:
        y += err * rng.randn(N) 
    return X, y

X, y = make_data(40)


%matplotlib inline
import matplotlib.pyplot as plt
import seaborn; seaborn.set() # 设置图形样式 
X_test = np.linspace(-0.1, 1.1, 500)[:, None]
plt.scatter(X.ravel(), y, color='black') 
axis = plt.axis()
for degree in [1, 3, 5]:
    y_test = PolynomialRegression(degree).fit(X, y).predict(X_test)
    plt.plot(X_test.ravel(), y_test, label='degree={0}'.format(degree))
plt.xlim(-0.1, 1.0)
plt.ylim(-2, 12)
plt.legend(loc='best'); 


from sklearn.model_selection import validation_curve

degree = np.arange(0, 21)

train_score, val_score = validation_curve(PolynomialRegression(), X, y,
'polynomialfeatures__degree', degree, cv=7)

plt.plot(degree, np.median(train_score, 1), color='blue', label='training score') 
plt.plot(degree, np.median(val_score, 1), color='red', label='validation score') 
plt.legend(loc='best')
plt.ylim(0, 1)
plt.xlabel('degree') 
plt.ylabel('score')
</code></pre>

<h3 id="学习曲线">学习曲线</h3>

<blockquote>
<p>反映训练集规模的训练得分 / 验证得分曲 线被称为学习曲线(learning curve)</p>

<p>学习曲线最重要的特征是，随着训练样本数量的增加，分数会收敛到定值。因此，一旦你的数据多到使模型得分已经收敛，那么增加更多的训练样本也无济于事!</p>
</blockquote>

<pre><code class="language-python">from sklearn.model_selection import learning_curve
fig, ax = plt.subplots(1, 2, figsize=(16, 6)) 
fig.subplots_adjust(left=0.0625, right=0.95, wspace=0.1)
for i, degree in enumerate([2, 9]):
    N, train_lc, val_lc = learning_curve(PolynomialRegression(degree), X, y, cv=7, train_sizes=np.linspace(0.3, 1, 25))
    ax[i].plot(N, np.mean(train_lc, 1), color='blue', label='training score') 
    ax[i].plot(N, np.mean(val_lc, 1), color='red', label='validation score') 
    ax[i].hlines(np.mean([train_lc[-1], val_lc[-1]]), N[0], N[-1], color='gray',linestyle='dashed')
    ax[i].set_ylim(0, 1)
    ax[i].set_xlim(N[0], N[-1])
    ax[i].set_xlabel('training size') 
    ax[i].set_ylabel('score')
    ax[i].set_title('degree = {0}'.format(degree), size=14) 
    ax[i].legend(loc='best')
</code></pre>

<blockquote>
<p>为模型和数据集画出学习曲线，可以帮你找到正确的方向，不断改进学习的效果</p>
</blockquote>

<h2 id="特征工程">特征工程</h2>

<p>向量化: 把任意格式的数据转换成具有良好特性的向量形式</p>

<h3 id="分类特征">分类特征</h3>

<blockquote>
<p>独热编码. 它可以有效增加额外的列，让 0 和 1 出现在 对应的列分别表示每个分类值有或无.</p>
</blockquote>

<p>如果数据是像字典列表时, 可以用 SKLearn 的 DictVectorizer 实现</p>

<pre><code class="language-python">from sklearn.feature_extraction import DictVectorizer 
# 适合当量字典型数据
vec = DictVectorizer(sparse=False, dtype=int) 
# 如果有大量字典(枚举值), 那可以用稀疏矩阵
# vec = DictVectorizer(sparse=True, dtype=int) 

data = [
                {'price': 850000, 'rooms': 4, 'neighborhood': 'Queen Anne'},
                {'price': 700000, 'rooms': 3, 'neighborhood': 'Fremont'},
                {'price': 650000, 'rooms': 3, 'neighborhood': 'Wallingford'},
                {'price': 600000, 'rooms': 2, 'neighborhood': 'Fremont'}
]
vec.fit_transform(data)

# 查看每一列的含义
vec.get_feature_names()
</code></pre>

<h3 id="文本特征">文本特征</h3>

<p>单词统计 <code>CountVectorizer</code></p>

<pre><code class="language-python">from sklearn.feature_extraction.text import CountVectorizer

vec = CountVectorizer()

sample = ['problem of evil',
       		'evil queen',
          'horizon problem']
X = vec.fit_transform(sample) 
X

import pandas as pd
pd.DataFrame(X.toarray(), columns=vec.get_feature_names())
</code></pre>

<p>原始的单词统计会让一些常用词聚集太高的权重，在分类算法中这样并不合理。解决这个问题的方法就是通过 TF–IDF(term frequency–inverse document frequency，词频逆文档频率)，通过单词在文档中出现的频率来衡量其权重. <code>IDF 的大小与一个词的常见程度成反比</code></p>

<pre><code class="language-python">from sklearn.feature_extraction.text import TfidfVectorizer 

vec = TfidfVectorizer()
sample = ['problem of evil',
                      'evil queen',
                      'horizon problem']

X = vec.fit_transform(sample)
pd.DataFrame(X.toarray(), columns=vec.get_feature_names())
</code></pre>

<h3 id="图像特征">图像特征</h3>

<p><a href="http://scikit-image.org">http://scikit-image.org</a></p>

<h3 id="缺失值填充">缺失值填充</h3>

<p>对于一般的填充方法，如均值、 中位数、众数，Scikit-Learn 有 <code>SimpleImputer</code> 类可以实现:</p>

<pre><code class="language-python">from numpy import nan
X = np.array([[ nan, 0, 3], [ 3, 7, 9], [ 3, 5, 2], [4, nan, 6], [8, 8, 1] ])
y = np.array([14, 16, -1, 8, -5])

from sklearn.impute import SimpleImputer 
imp = SimpleImputer(missing_values=np.nan, strategy='mean')
X2 = imp.fit_transform(X) 
X2
</code></pre>

<h2 id="朴素贝叶斯分类">朴素贝叶斯分类</h2>

<blockquote>
<p>之所以称为“朴素”或“朴素贝叶斯”，是因为如果对每种标签的生成模型进行非常简单 的假设，就能找到每种类型生成模型的近似解，然后就可以使用贝叶斯分类.</p>

<p>贝叶斯主义(Bayesian formalism)的一个优质特性是它天生支持概率分类</p>
</blockquote>

<p>$$
P(L | 特征) = \frac{P(特征|L) P(L)}{P(特征)}
$$</p>

<h3 id="高斯朴素贝叶斯">高斯朴素贝叶斯</h3>

<blockquote>
<p>假设每个标签的数据都服从简单的高斯分布</p>
</blockquote>

<pre><code class="language-python">%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt 
import seaborn as sns; sns.set()

# 数据训练数据, 可视化它
from sklearn.datasets import make_blobs
X, y = make_blobs(100, 2, centers=2, random_state=2, cluster_std=1.5) 
plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu')

# 选择模型, 拟合
from sklearn.naive_bayes import GaussianNB 
model = GaussianNB()
model.fit(X, y)

# 生成新数据来预测标签
rng = np.random.RandomState(0)
Xnew = [-6, -14] + [14, 18] * rng.rand(2000, 2) 
ynew = model.predict(Xnew)

# 将这些新数据画出来，看看决策边界的位置
plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='RdBu') 
lim = plt.axis()
plt.scatter(Xnew[:, 0], Xnew[:, 1], c=ynew, s=20, cmap='RdBu', alpha=0.1) 
plt.axis(lim)

# 后验概率
yprob = model.predict_proba(Xnew) 
yprob[-8:].round(2)
</code></pre>

<h3 id="多项式朴素贝叶斯">多项式朴素贝叶斯</h3>

<p><code>multinomial naive Bayes</code></p>

<blockquote>
<p>多项式朴素贝叶斯非常 适合用于描述出现次数或者出现次数比例的特征。</p>
</blockquote>

<pre><code class="language-python"># 下载测试数据
from sklearn.datasets import fetch_20newsgroups
data = fetch_20newsgroups() 
data.target_names

# 只测试以下四类
categories = ['talk.religion.misc', 'soc.religion.christian', 'sci.space',
'comp.graphics']
# 下载测试数据和训练数据
train = fetch_20newsgroups(subset='train', categories=categories) test = fetch_20newsgroups(subset='test', categories=categories)

# 创建模型
from sklearn.feature_extraction.text import TfidfVectorizer 
from sklearn.naive_bayes import MultinomialNB
from sklearn.pipeline import make_pipeline

model = make_pipeline(TfidfVectorizer(), MultinomialNB())

# 拟合
model.fit(train.data, train.target) 
labels = model.predict(test.data)

# 用混淆矩阵统计测试真实标签与预测标签
from sklearn.metrics import confusion_matrix
mat = confusion_matrix(test.target, labels)

sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,
xticklabels=train.target_names, yticklabels=train.target_names) 

plt.xlabel('true label')
plt.ylabel('predicted label');

# 生成了模型, 调用函数来测试输入数据
def predict_category(s, train=train, model=model): 
  pred = model.predict([s])
	return train.target_names[pred[0]]

predict_category('sending a payload to the ISS')
</code></pre>

<h2 id="线性回归">线性回归</h2>

<pre><code class="language-python">%matplotlib inline
import matplotlib.pyplot as plt 
import seaborn as sns; sns.set() 
import numpy as np

# 生成测试数据
rng = np.random.RandomState(1) 
x = 10 * rng.rand(50)
y = 2 * x - 5 + rng.randn(50) 
plt.scatter(x, y)

# 选择模型, 及拟合, 预测
from sklearn.linear_model import LinearRegression
model = LinearRegression(fit_intercept=True) 
model.fit(x[:, np.newaxis], y)
xfit = np.linspace(0, 10, 1000)
yfit = model.predict(xfit[:, np.newaxis])
plt.scatter(x, y) 
plt.plot(xfit, yfit)

# 查看截距(intercept)和斜率(slope)
print(&quot;Model slope: &quot;, model.coef_[0]) 
print(&quot;Model intercept:&quot;, model.intercept_)

# 多维度线性回归
rng = np.random.RandomState(1)
X = 10 * rng.rand(100, 3)
y = 0.5 + np.dot(X, [1.5, -2., 1.])
model.fit(X, y) 
print(model.intercept_) 
print(model.coef_)
</code></pre>

<h2 id="支持向量机-svm">支持向量机 SVM</h2>

<blockquote>
<p>有监督学习算法，既可 用于分类，也可用于回归</p>
</blockquote>

<p>不再画一条细线来区分类 型，而是画一条到最近点边界、有宽度的线条.</p>

<p>支持向量机其实就是一个边界最大化评估器。</p>

<h1 id="杂项">杂项</h1>

<p>向量化处理新数据</p>

<pre><code class="language-python"># data 是向量化后的数据
data = vec.fit_transform(df.to_dict( orient = 'records' ))

# 处理新数据
newData = vec.transform(newClick.to_dict( orient = 'records' ))
</code></pre>

    </div>

    
    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">emacsist</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">2020-03-28</span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">License</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>

    
    
<div class="post-reward">
  <input type="checkbox" name="reward" id="reward" hidden />
  <label class="reward-button" for="reward">Reward</label>
  <div class="qr-code">
    
    
      <label class="qr-code-image" for="reward">
        <img class="image" src="/img/wxpay.jpeg">
        <span>wechat</span>
      </label>
    
      <label class="qr-code-image" for="reward">
        <img class="image" src="/img/alipay.jpeg">
        <span>alipay</span>
      </label>
  </div>
</div>

    <footer class="post-footer">
      <div class="post-tags">
          
          <a href="/tags/python/">python</a>
          
          <a href="/tags/%E6%95%B0%E6%8D%AE/">数据</a>
          
        </div>

      
      <nav class="post-nav">
        
          <a class="prev" href="https://emacsist.github.io/2020/03/29/pandas%E6%9D%82%E9%A1%B9/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Pandas杂项</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        
          <a class="next" href="https://emacsist.github.io/2020/03/22/jq%E5%AD%A6%E4%B9%A0/">
            <span class="next-text nav-default">Jq学习</span>
            <span class="prev-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        
  <div id="comments-gitment"></div>
  <link rel="stylesheet" href="/lib/gitment/gitment-0.0.3.min.css">
    <script src="/lib/gitment/gitment-0.0.3.min.js"></script>
  <script type="text/javascript">
  const gitment = new Gitment({
    id: '2020-03-28 22:44:37 \x2b0800 CST',
    title: '\x3cPython数据科学手册\x3e笔记',
    link: decodeURI(location.href),
    desc: '数据科学概念 它综合了三个领域的能力 统计学家 : 建立模型和聚合数',
    owner: 'emacsist',
    repo: 'emacsist.github.io',
    oauth: {
      client_id: 'd1456501fba5329f3afa',
      client_secret: 'd1ecbb7929a49de947215701320c60b312a72d3a'
    }
  })
  gitment.render('comments-gitment')
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://github.com/imsun/gitment">comments powered by gitment.</a></noscript>

  

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:emacsist@qq.com" class="iconfont icon-email" title="email"></a>
      <a href="https://twitter.com/emacsist2016" class="iconfont icon-twitter" title="twitter"></a>
      <a href="https://plus.google.com/u/0/114200054463267049438" class="iconfont icon-google" title="google"></a>
      <a href="https://github.com/emacsist" class="iconfont icon-github" title="github"></a>
      <a href="https://www.zhihu.com/people/emacist" class="iconfont icon-zhihu" title="zhihu"></a>
      <a href="https://www.douban.com/people/emacsist/" class="iconfont icon-douban" title="douban"></a>
  <a href="https://emacsist.github.io/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  <div class="busuanzi-footer">
    <span id="busuanzi_container_site_pv"> site pv: <span id="busuanzi_value_site_pv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
    <span class="division">|</span>
    <span id="busuanzi_container_site_uv"> site uv: <span id="busuanzi_value_site_uv"><img src="/img/spinner.svg" alt="spinner.svg"/></span> </span>
  </div>


  <span class="copyright-year">
    &copy; 
    
      2014 - 
    2020
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">emacsist</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
<script src="/lib/highlight/highlight.pack.js?v=20171001"></script><script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>
  
<script type="text/javascript" src="/dist/even.min.js?v=3.1.1"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML"></script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-118327923-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>









<script type="text/javascript">var cnzz_protocol = (("https:" == document.location.protocol) ? "https://" : "http://");document.write(unescape("%3Cspan id='cnzz_stat_icon_1278300546'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s4.cnzz.com/z_stat.php%3Fid%3D1278300546%26show%3Dpic' type='text/javascript'%3E%3C/script%3E"));</script>
</body>
</html>
